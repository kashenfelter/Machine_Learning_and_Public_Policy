---
title: "Notes from PBPL 28820"
author: "Cristian E. Nuno"
date: "`r format( x = Sys.Date(), format = '%B %d, %Y')`"
output: 
  github_document:
    toc: true
    toc_depth: 2
    dev: png
---

```{r Load ISLR}
# load necessary packages
# install.packages( pkgs = "ISLR" )
library( ISLR )
```

# Preface

> “It’s tough to make predictions, especially about the future.” – Yogi Berra

# Introduction

* Statistical learning = understanding data
    + Supervised: Building a statistical model for predicting, or estimating, an output based on one or more inputs
    + Unsupervised: There are inputs but no supervising output

## Wage Data

In particular, we wish to understand the association between an employee’s age and education, as well as the calendar year, on his wage.

The `Wage` data set involves predicting a **continuous** or **quantitative** output value, which is referred to as a **regression** problem.

```{r Wage Plots}
# age v wage
plot(
  x = Wage$age
  , y = Wage$wage
  , pch = 19
  , col = "#CCCCCC"
  , main = "Age v. Wage"
  , xlab = "Age"
  , ylab = "Wage"
  , las = 1
  , bty = "n"
)
lines( 
  x = lowess(
    x = Wage$age
    , y = Wage$wage
  )
  , col = "darkgoldenrod2"
  , lwd = 4
)

# year v wage
plot(
  x = Wage$year
  , y = Wage$wage
  , las = 1
  , pch = 19
  , col = "#CCCCCC"
  , main = "Year v. Wage"
  , xlab = "Year"
  , ylab = "Wage"
  , bty = "n"
)
lines(
  x = lowess(
    x = Wage$year
    , y = Wage$wage
  )
  , col = "darkgoldenrod2"
  , lwd = 2
)

# education level v wage
boxplot(
  formula = wage~education
  , data = Wage
  , las = 1
  , frame = FALSE
  , col = rainbow( n = length( levels( Wage$education ) ) )
  , main = "Distribution of Wages by Education Level"
  , xaxt = "n"
)
axis(
  side = 1
  , at = 1:length( levels( Wage$education ) )
  , labels = 1:length( levels( Wage$education ) )
)
legend(
  x = "topleft"
  , legend = levels( Wage$education )
  , col = rainbow( n = length( levels( Wage$education ) ) )
  , bty = "n"
  , pch = 15
  , cex = 0.85
  , title = "Education Levels"
)
```

## Stock Market Data

When we wish to predict a non-numerical value - a **categorical** or **qualitative** output, this is known as a **classification** problem. 

```{r Stock Barplots}
down.up.color.schema <-
  c("dodgerblue", "firebrick")

par( mfrow = c( nr = 1, nc = 3 ) )
# yesterday's change in S&P
boxplot(
  formula = Lag1~Direction
  , data = Smarket
  , frame = FALSE
  , col = down.up.color.schema
  , main = "Yesterday"
  , ylab = "% Change in S&P"
  , xlab = "Today's Direction"
)
boxplot(
  formula = Lag2~Direction
  , data = Smarket
  , frame = FALSE
  , col = down.up.color.schema
  , main = "Two Days Previous"
  , ylab = "% Change in S&P"
  , xlab = "Today's Direction"
)
boxplot(
  formula = Lag3~Direction
  , data = Smarket
  , frame = FALSE
  , col = down.up.color.schema
  , main = "Three Days Previous"
  , ylab = "% Change in S&P"
  , xlab = "Today's Direction"
)
```

## Gene Expression Data

The previous two applications illustrate data sets with both input and output variables.

There are situations in which we *only observe input variables, with no corresponding output*.

* Ex: market setting uses demographic data to understand which types of current customers are similar to one another by **grouping individuals according to their observed characteristics**. This is known as a *clustering* problem.

### Principal Component Analysis

The following visualization is an example of [principal component analysis](https://tgmstat.wordpress.com/2013/11/21/introduction-to-principal-component-analysis-pca/).

```{r Gene Expression Scatter Plots}

# Z1 v Z2

```




